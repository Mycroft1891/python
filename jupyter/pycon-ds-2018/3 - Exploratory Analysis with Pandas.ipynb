{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "That's it for some preliminary cleaning. Don't worry, there will be more. Let's start to look in a bit more detail at the data, though. In this section, we're going to start to write some code that's typical for day-to-day data cleaning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import dta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `info` to get some high-level information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 68091 to 2009279\n",
      "Data columns (total 15 columns):\n",
      "address            25000 non-null object\n",
      "aka_name           24731 non-null object\n",
      "city               24978 non-null object\n",
      "dba_name           25000 non-null object\n",
      "facility_type      24565 non-null category\n",
      "inspection_date    25000 non-null datetime64[ns]\n",
      "inspection_type    25000 non-null category\n",
      "latitude           24822 non-null float64\n",
      "license_           24999 non-null float64\n",
      "longitude          24822 non-null float64\n",
      "results            25000 non-null category\n",
      "risk               24991 non-null category\n",
      "state              24995 non-null object\n",
      "violations         19538 non-null object\n",
      "zip                24991 non-null object\n",
      "dtypes: category(4), datetime64[ns](1), float64(3), object(7)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dta.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `describe` goes into a bit more detail for the *numeric* types, of which we don't have many here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>license_</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24822.000000</td>\n",
       "      <td>2.499900e+04</td>\n",
       "      <td>24822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.879724</td>\n",
       "      <td>1.566116e+06</td>\n",
       "      <td>-87.676341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081331</td>\n",
       "      <td>8.968458e+05</td>\n",
       "      <td>0.058746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.644670</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-87.914428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.830500</td>\n",
       "      <td>1.167576e+06</td>\n",
       "      <td>-87.708082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.891055</td>\n",
       "      <td>1.959049e+06</td>\n",
       "      <td>-87.665706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.939776</td>\n",
       "      <td>2.215768e+06</td>\n",
       "      <td>-87.634955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.021064</td>\n",
       "      <td>8.700606e+06</td>\n",
       "      <td>-87.525094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude      license_     longitude\n",
       "count  24822.000000  2.499900e+04  24822.000000\n",
       "mean      41.879724  1.566116e+06    -87.676341\n",
       "std        0.081331  8.968458e+05      0.058746\n",
       "min       41.644670  0.000000e+00    -87.914428\n",
       "25%       41.830500  1.167576e+06    -87.708082\n",
       "50%       41.891055  1.959049e+06    -87.665706\n",
       "75%       41.939776  2.215768e+06    -87.634955\n",
       "max       42.021064  8.700606e+06    -87.525094"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do the same for the categorical types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_type</th>\n",
       "      <th>inspection_type</th>\n",
       "      <th>results</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24565</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>24991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>244</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Canvass</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Risk 1 (High)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>16666</td>\n",
       "      <td>12305</td>\n",
       "      <td>15827</td>\n",
       "      <td>17885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       facility_type inspection_type results           risk\n",
       "count          24565           25000   25000          24991\n",
       "unique           244              45       7              4\n",
       "top       Restaurant         Canvass    Pass  Risk 1 (High)\n",
       "freq           16666           12305   15827          17885"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.select_dtypes(['category']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's ask the most obvious question. Which are the best and the worst restaurants? We'll want to use pandas `GroupBy` functionality to implement the `split-apply-combine` pattern.\n",
    "\n",
    "The idea here is that we **split** the data by some key or set of keys then **apply** a function to each group and then **combine** the outputs back into a single DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how many result categories there are. We can use `value_counts` to answer this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass                    15827\n",
      "Fail                     4876\n",
      "Pass w/ Conditions       2396\n",
      "Out of Business          1088\n",
      "No Entry                  547\n",
      "Not Ready                 263\n",
      "Business Not Located        3\n",
      "Name: results, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with pd.option_context(\"max.rows\", 10):\n",
    "    print(dta.results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's group on the inspection `results` column and see who the best and worst are.\n",
    "\n",
    "When we call the `groupby` method we get back a `DataFrameGroupBy` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = dta.groupby(dta.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x113df6780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the variables on this object, the same as a DataFrame, and any code called will execute within the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grouper.dba_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a Series with a `MultiIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results               dba_name                                          \n",
       "Business Not Located  CITGO SUPER WASH & GAS                                 1\n",
       "                      KAIYO                                                  1\n",
       "                      NANNY'S WAFFALS HOUSE                                  1\n",
       "Fail                  SUBWAY                                                41\n",
       "                      DUNKIN DONUTS                                         33\n",
       "                      MCDONALD'S                                            23\n",
       "                      MCDONALDS                                              9\n",
       "                      PIZZA HUT                                              9\n",
       "                      7-ELEVEN                                               7\n",
       "                      AU BON PAIN                                            7\n",
       "                      DOMINO'S PIZZA                                         7\n",
       "                      HAROLD'S CHICKEN SHACK                                 7\n",
       "                      PANERA BREAD                                           7\n",
       "                      SOHO HOUSE                                             7\n",
       "                      SUBWAY SANDWICHES                                      7\n",
       "                      CHIPOTLE MEXICAN GRILL                                 6\n",
       "                      JIMMY JOHNS                                            6\n",
       "                      McDONALD'S                                             6\n",
       "                      PALETERIA Y NEVERIA LA MEXICANA YOGURT AND CHURRO      6\n",
       "                      POTBELLY SANDWICH WORKS                                6\n",
       "                      POTBELLY SANDWICH WORKS LLC                            6\n",
       "                      DUNKIN DONUTS / BASKIN ROBBINS                         5\n",
       "                      DUNKIN DONUTS/BASKIN ROBBINS                           5\n",
       "                      JIMMY G'S                                              5\n",
       "                      MARATHON                                               5\n",
       "                      ONE STOP FOOD & GROCERY                                5\n",
       "                      RED SNAPPER                                            5\n",
       "                      SEE THRU CHINESE KITCHEN                               5\n",
       "                      Subway                                                 5\n",
       "                      TRIPLE A SERVICES, INC.                                5\n",
       "                                                                            ..\n",
       "Pass w/ Conditions    WINCHESTER MINI MART                                   1\n",
       "                      WING CHONG RESTAURANT                                  1\n",
       "                      WING YIP RESTAURANT                                    1\n",
       "                      WINGS & FINS                                           1\n",
       "                      WINGSTOP                                               1\n",
       "                      WINGSTOP #587                                          1\n",
       "                      WOK THIS WAY RESTAURANT                                1\n",
       "                      WOLFGANG EXPRESS                                       1\n",
       "                      WOLFGANG PUCK CATERING & EVENTS AT SPERTUS INSTITU     1\n",
       "                      WOLVERINE TRADING LLC                                  1\n",
       "                      WOMAN'S ATHLETIC CLUB OF CHICAGO                       1\n",
       "                      WONG'S ASIA CAFE                                       1\n",
       "                      WONUT                                                  1\n",
       "                      WOODIE'S FLAT                                          1\n",
       "                      WOODLAWN FOOD MARTKET                                  1\n",
       "                      Walgreens # 02340                                      1\n",
       "                      Walter Newberry Elementary                             1\n",
       "                      XOCO                                                   1\n",
       "                      YES                                                    1\n",
       "                      YIN DEE RESTAURANT                                     1\n",
       "                      YOLANDA'S RESTAURANT INC                               1\n",
       "                      YOLK CAFE                                              1\n",
       "                      YUEN'S  CHINESE  KITCHEN                               1\n",
       "                      YUEN'S CHINESE KITCHEN                                 1\n",
       "                      YUMMY BUFFET                                           1\n",
       "                      Yassa African Carribean Resturant                      1\n",
       "                      ZACAGUISOS INC.                                        1\n",
       "                      ZACATACOS                                              1\n",
       "                      ZAKI CHICAGO STYLE GRILLE                              1\n",
       "                      ZBERRY                                                 1\n",
       "Name: dba_name, Length: 16981, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.index.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index on the first element in a `MultiIndex` using square brackets and then use `sort_values` to find those restaurants that had a result of Fail the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('max.rows', 15):\n",
    "    print(result[\"Fail\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a closer look above. Looks like we have some more data cleaning to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('max.rows', 15):\n",
    "    print(result[\"Pass\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably not the right way to think about this since there are many more Subways than local establishments.\n",
    "\n",
    "We could instead look at the ratio of Fail to Pass, though, of course, this isn't perfect either. \n",
    "\n",
    "Sometimes, it's not *always* obvious how to go about computing things that you want to compute. The `get_group` method allows you to pull out one of the split DataFrames and try your apply function on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "GroupBy the `dba_name`. Use `get_group` to pull out the \"MCDONALD'S\" group. Write a function that calculates the relative number of Fail to Pass for this group. Run this function on the McDonald's group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/get_group.py\n",
    "grouper = dta.groupby(dta.dba_name)\n",
    "mcd = grouper.get_group(\"MCDONALD'S\")\n",
    "\n",
    "\n",
    "def relative_results(df):\n",
    "    values = df.value_counts()\n",
    "    return values['Fail'] / values['Pass']\n",
    "\n",
    "\n",
    "relative_results(mcd.results)\n",
    "\n",
    "# And we see McDonald's failed 50% as many inspections as it Passed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this on everything, but it's going to be a little slow. Let's look at another way to approach this problem.\n",
    "\n",
    "Here group by *both* the inspection results and the DBA name. Then we ask for the `size` of each one of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Interpreting tuple 'by' as a list of keys, rather than a single key. Use 'by=[...]' instead of 'by=(...)'. In the future, a tuple will always mean a single key.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result = dta.groupby((dta.results, dta.dba_name)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results               dba_name                                          \n",
       "Business Not Located  CITGO SUPER WASH & GAS                                1\n",
       "                      KAIYO                                                 1\n",
       "                      NANNY'S WAFFALS HOUSE                                 1\n",
       "Fail                  #1 CHOP SUEY                                          2\n",
       "                      #1 WOK N ROLL                                         1\n",
       "                      1 N WACKER KITCHEN AND BAR                            1\n",
       "                      111 TH FOOD & CELLULAR, INC                           1\n",
       "                      111TH AND RACINE MARATHON, INC.                       1\n",
       "                      111TH STREET OTB                                      1\n",
       "                      12 WEST ELM                                           1\n",
       "                      123 MINI MART                                         1\n",
       "                      13 Pins Tapas & Grill                                 1\n",
       "                      1492 TAPAS                                            1\n",
       "                      16TH & MILLARD FOOD                                   1\n",
       "                      16TH ST FOOD MART                                     1\n",
       "                      18TH STREET FOOD MART                                 1\n",
       "                      1914 CLUB                                             2\n",
       "                      194  RIB  JOYNT                                       1\n",
       "                      1ST FRUITS ACADEMY INC                                1\n",
       "                      2 ASIAN BROTHERS                                      1\n",
       "                      2002 DONUTS INC                                       1\n",
       "                      2012 FOOD MART INC                                    1\n",
       "                      24 FOODS                                              1\n",
       "                      24 GRILL                                              1\n",
       "                      24 HOURS FOOD MART                                    1\n",
       "                      260 SPORTS BAR                                        1\n",
       "                      3 GREENS MARKET                                       1\n",
       "                      3 JJJ'S BETTER TASTE JAMAICAN JERK RESTAURANT         1\n",
       "                      3 SQUARES                                             1\n",
       "                      300 CONVENIENCE                                       2\n",
       "                                                                           ..\n",
       "Pass w/ Conditions    WOK THIS WAY RESTAURANT                               1\n",
       "                      WOLFGANG EXPRESS                                      1\n",
       "                      WOLFGANG PUCK CATERING & EVENTS AT SPERTUS INSTITU    1\n",
       "                      WOLVERINE TRADING LLC                                 1\n",
       "                      WOMAN'S ATHLETIC CLUB OF CHICAGO                      1\n",
       "                      WONG'S ASIA CAFE                                      1\n",
       "                      WONUT                                                 1\n",
       "                      WOODIE'S FLAT                                         1\n",
       "                      WOODLAWN FOOD MARTKET                                 1\n",
       "                      WRIGLEYVILLE DAIRY QUEEN                              2\n",
       "                      Walgreens # 02340                                     1\n",
       "                      Walmart Neighborhood Market #5646                     2\n",
       "                      Walter Newberry Elementary                            1\n",
       "                      XANDO COFFEE & BAR / COSI SANDWICH BAR                2\n",
       "                      XOCO                                                  1\n",
       "                      XSPORT FITNESS                                        2\n",
       "                      YES                                                   1\n",
       "                      YIN DEE RESTAURANT                                    1\n",
       "                      YOLANDA'S RESTAURANT INC                              1\n",
       "                      YOLK CAFE                                             1\n",
       "                      YON'S DELI                                            2\n",
       "                      YUEN'S  CHINESE  KITCHEN                              1\n",
       "                      YUEN'S CHINESE KITCHEN                                1\n",
       "                      YUMMY BUFFET                                          1\n",
       "                      Yango's Grill                                         2\n",
       "                      Yassa African Carribean Resturant                     1\n",
       "                      ZACAGUISOS INC.                                       1\n",
       "                      ZACATACOS                                             1\n",
       "                      ZAKI CHICAGO STYLE GRILLE                             1\n",
       "                      ZBERRY                                                1\n",
       "Length: 16981, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `div` method to divide these for us. As you can see the indices don't line up, but we don't have to worry about it. Pandas take care of index alignment for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dba_name\n",
       "#1 CHOP SUEY                                     2\n",
       "#1 WOK N ROLL                                    1\n",
       "1 N WACKER KITCHEN AND BAR                       1\n",
       "111 TH FOOD & CELLULAR, INC                      1\n",
       "111TH AND RACINE MARATHON, INC.                  1\n",
       "111TH STREET OTB                                 1\n",
       "12 WEST ELM                                      1\n",
       "123 MINI MART                                    1\n",
       "13 Pins Tapas & Grill                            1\n",
       "1492 TAPAS                                       1\n",
       "16TH & MILLARD FOOD                              1\n",
       "16TH ST FOOD MART                                1\n",
       "18TH STREET FOOD MART                            1\n",
       "1914 CLUB                                        2\n",
       "194  RIB  JOYNT                                  1\n",
       "1ST FRUITS ACADEMY INC                           1\n",
       "2 ASIAN BROTHERS                                 1\n",
       "2002 DONUTS INC                                  1\n",
       "2012 FOOD MART INC                               1\n",
       "24 FOODS                                         1\n",
       "24 GRILL                                         1\n",
       "24 HOURS FOOD MART                               1\n",
       "260 SPORTS BAR                                   1\n",
       "3 GREENS MARKET                                  1\n",
       "3 JJJ'S BETTER TASTE JAMAICAN JERK RESTAURANT    1\n",
       "3 SQUARES                                        1\n",
       "300 CONVENIENCE                                  2\n",
       "3600 COMMISSARY                                  1\n",
       "3756-58 W. NORTH, INC.                           1\n",
       "38 LITTLE ANGELS HOME DAYCARE                    1\n",
       "                                                ..\n",
       "YU XIANG GOURMET                                 1\n",
       "YUKI  HANA                                       1\n",
       "YUMMY BUFFET                                     2\n",
       "YUMMY YUMMY NOODLES                              1\n",
       "YUMMY YUMMY NOODLES, INC.                        2\n",
       "YURI'S TAQUERIA                                  1\n",
       "YURY'S TAQUERIA                                  1\n",
       "Yassa African Carribean Resturant                1\n",
       "Youmax Food & Liquor                             1\n",
       "Young Elementary                                 1\n",
       "Z-A PIZZA                                        1\n",
       "ZACA'S OF MIDWAY                                 1\n",
       "ZACAGUISOS INC.                                  1\n",
       "ZACAS OF MIDWAY                                  1\n",
       "ZACHI INC                                        1\n",
       "ZAIQA INDIAN RESTAURANT                          2\n",
       "ZALESKI & HORVATH MARKETCAFE, LTD.               1\n",
       "ZAMZAM BANQUET HALL                              2\n",
       "ZAPATISTA                                        3\n",
       "ZBERRY                                           2\n",
       "ZED 451                                          1\n",
       "ZERO DEGREES KARAOKE BAR LLC                     2\n",
       "ZIGZAG CAFE                                      1\n",
       "ZIP'Z EXPRESS FAST FOOD                          1\n",
       "ZOKU SUSHI                                       1\n",
       "ZOOTS                                            1\n",
       "ZU'S QUICK MART                                  1\n",
       "bopNgrill                                        1\n",
       "mcdonalds                                        1\n",
       "rendezvous bistro                                1\n",
       "Length: 3943, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"Fail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"Pass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dba_name\n",
       "JACK'S ON HALSTED                                    4.000000\n",
       "NORTHSTAR COFFEE                                     4.000000\n",
       "O'LEARY'S PUBLIC HOUSE                               3.000000\n",
       "KING GYROS                                           3.000000\n",
       "PILSEN ELEMENTARY                                    3.000000\n",
       "SOUTH SHORE INTERNATIONAL COLLEGE PREP               3.000000\n",
       "ROSELAND FOOD & LIQUOR                               3.000000\n",
       "FERNANDO'S RESTAURANT                                3.000000\n",
       "MELROSE RESTAURANT                                   3.000000\n",
       "FAIRPLAY FOODS                                       3.000000\n",
       "PALETERIA Y NEVERIA LA MEXICANA YOGURT AND CHURRO    3.000000\n",
       "TAMALLI SPACE CHARROS LLC                            3.000000\n",
       "THE GODDESS AND GROCER                               3.000000\n",
       "TABO SUSHI                                           3.000000\n",
       "SUBWAY 3634                                          3.000000\n",
       "EL FARO RESTAURANT                                   3.000000\n",
       "NUEVO LEON RESTAURANT                                3.000000\n",
       "DONA NATYS TACOS                                     3.000000\n",
       "SWIFT  ELEMENTARY SCHOOL                             3.000000\n",
       "PARK  PLAZA RETIREMENT CENTER                        3.000000\n",
       "CITGO GAS                                            3.000000\n",
       "LAS TABLAS ON LINCOLN                                3.000000\n",
       "CHAN'S RESTAURANT                                    3.000000\n",
       "ZAPATISTA                                            3.000000\n",
       "RED SNAPPER                                          2.500000\n",
       "JIMMY G'S                                            2.500000\n",
       "PANERA BREAD                                         2.333333\n",
       "CHICAGO DINER LOGAN SQUARE                           2.000000\n",
       "TABLE FIFTY-TWO                                      2.000000\n",
       "THE PARTHENON RESTAURANT INC                         2.000000\n",
       "                                                       ...   \n",
       "ZAKI CHICAGO STYLE GRILLE                                 NaN\n",
       "ZALESKI & HORVATH MARKETCAFE                              NaN\n",
       "ZAMZAM BANQUET HALL                                       NaN\n",
       "ZANZABAR                                                  NaN\n",
       "ZANZIBAR CAFE AND ICE CREAM SHOPPE                        NaN\n",
       "ZAVEN INC                                                 NaN\n",
       "ZAYNS MARKET & DELI INC.                                  NaN\n",
       "ZBERRY                                                    NaN\n",
       "ZED 451                                                   NaN\n",
       "ZENTRA                                                    NaN\n",
       "ZERO DEGREES KARAOKE BAR LLC                              NaN\n",
       "ZIA'S LAGO VISTA                                          NaN\n",
       "ZIAD CERTIFIED FOODS                                      NaN\n",
       "ZIG ZAG KITCHEN                                           NaN\n",
       "ZIGGY'S SIDE DOOR PUB & DELI                              NaN\n",
       "ZIGZAG CAFE                                               NaN\n",
       "ZORIANA CANDY STORE INC.                                  NaN\n",
       "ZOUP!                                                     NaN\n",
       "ZU'S QUICK MART                                           NaN\n",
       "ZULLO'S INC.                                              NaN\n",
       "ZULLO'S MARKETS, LLC                                      NaN\n",
       "Zaytune Mediterranean Grill                               NaN\n",
       "Zia's Trattoria                                           NaN\n",
       "cardona's 2                                               NaN\n",
       "food & paper supply co                                    NaN\n",
       "mcdonalds                                                 NaN\n",
       "mr.daniel's                                               NaN\n",
       "pars-persian store                                        NaN\n",
       "rendezvous bistro                                         NaN\n",
       "stockton                                                  NaN\n",
       "Length: 11097, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = result[\"Fail\"].div(result[\"Pass\"])\n",
    "ratio.sort_values(ascending=False, inplace=True)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of `NaN`s in the results from division-by-zero. We can drop those with a call to `dropna`. Also note that pandas lets you decide whether to treat `inf` as an NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"use_inf_as_null\", True,\n",
    "                       \"max.rows\", 15):\n",
    "    print(ratio.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might still not be wholly satisfied with our rules around comparisons here. First, we're looking at restaurant names not particular establishments. What does the distribution of inspection visits for establishments look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"max.rows\", 10):\n",
    "    grouper = dta.groupby((dta.address, dta.dba_name))\n",
    "    print(grouper.size().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's make things a little more challenging. Let's see what the Fail:Pass ratio is for restaurants with at least 3 visits that involved a high risk level. \n",
    "\n",
    "\n",
    "Now we're starting to get into some much more powerful pandas constructs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = (dta.query(\"risk == 'Risk 1 (High)'\")\n",
    "           .groupby(('address', 'dba_name'))\n",
    "           .size()\n",
    "           .rename('n_visits')\n",
    "           .reset_index()  # make into a DataFrame\n",
    "           .query(\"n_visits >= 4\"))\n",
    "\n",
    "visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack this. The first thing to note is how this code is organized. Each one of these methods return a pandas data structure on which we call the next method. This is called **method chaining**. We use the same trick seen above to split strings across lines to split several method calls by including the code between `()`.\n",
    "\n",
    "Next, we see several new methods. The first is **query**. When subsetting a DataFrame we have a few options. As we save above, we can index a DataFrame using integers. Likewise, we could pass an object of booleans as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.risk == \"Risk 1 (High)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.loc[dta.risk == \"Risk 1 (High)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always using indexing can be verbose, however. You may need compound statements, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.loc[(dta.risk == \"Risk 1 (High)\") | (dta.risk == \"Risk 1 (Medium)\")].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, by using query we could write the following, which is slightly easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.query(\"(risk == 'Risk 1 (High)') | (risk == 'Risk 1 (Medium)')\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use `query` to find the visits that are to restaurants and that are complaint re-inspections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/query.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "visited = (dta.query(\"risk == 'Risk 1 (High)'\")\n",
    "           .groupby(('address', 'dba_name'))\n",
    "           .size()\n",
    "           .rename('n_visits')  # size returns a nameless series\n",
    "           .reset_index()  # make into a DataFrame\n",
    "           .query(\"n_visits >= 4\"))\n",
    "```\n",
    "\n",
    "\n",
    "The next new method is the **rename** method. We use this to rename the unnamed Series returned by `size`.\n",
    "\n",
    "Finally, we filter on restaurants with 4 or more total visits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final piece is computing the Fail:Pass ratio of these restaurants. To do this, we need to take the output we've created `visited` and line our original data up with these addresses and DBA names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this by using the **merge** method. Merge allows us to make two pandas DataFrames into a single DataFrame. By default, the `merge` method will join together two DataFrames on common columns, using an inner join method (a set intersection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_visits = visited.merge(dta)\n",
    "merged_visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to redo the analysis we started above for McDonald's. We take these merged DataFrames, group them by the inspection results, the address, and the DBA name and ask for the size of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(merged_visits\n",
    " .groupby(('results', 'address', 'dba_name'))\n",
    " .size()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Take this result and **pipe** it (using the `pipe` method) to a function that computes Fail/Pass. Make sure your result does not have any missing values, and sort it such that those with the highest Fail/Pass ratios are highest.\n",
    "\n",
    "The **pipe** method allows for including user-defined functions in method chains. It takes the output of the thing on the left, and passes it to the thing on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/pipe_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Now, take everything that we've done above, from `dta` to this final result, and put it together into a single method chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/complete_chain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, I'll try to place a method chain to get the data ready for more exploratory work at the top of a notebook, so I can proceed with any analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go back to our original data and add in the unstacked violations to the information that's unchanging. Recall from the previous notebook that we unstack the violations as follows. There are two new things to note here though. We add in a `to_frame` method to turn the unstacked Series into a DataFrame, and we `rename` the unnamed column in the resulting DataFrame back to `violations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dta.violations\n",
    " .str.split(\"|\", expand=True)\n",
    " .unstack()\n",
    " .dropna()\n",
    " .reset_index(level=0, drop=True)\n",
    " .str.strip()\n",
    " .rename('violations')\n",
    " .to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to drop the violations from the original DataFrame, then we need to merge it with the unstacked violations Series that we created before. You can use `drop` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.drop([\"violations\"], axis='columns').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Drop the original violations from `dta`, and **join** this to the unstacked violations as computed above. You'll probably want to use a **right join**.\n",
    "\n",
    "We use **join** here rather than **merge**. Join uses merge under the hood but conveniently allows us to join on the indices of the two DataFrames by default. One other difference is that join uses an inner merge by default, but that's not what we want here. Since we drop the null violations on the right-hand side DataFrame, we want to do a right join. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/join_violations.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a relatively clean DataFrame, let's ask a few more questions. \n",
    "\n",
    "First, how many unique violations do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.violations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.violations.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this true? Do we really think there are this many violation numbers? Probably not. We can use the `str` accessor and some more munging to answer this. Here we pass a **regular expression** to `str.extract`. Extract expects a *capture group*, indicated by `()`. The regular expression `(\\d+\\)(?=\\.)` means capture 1 or more (`+`) digits (`\\d`) that is followed by (`(?=)`) a period `\\.`. We escape the period because a plain `.` is a wildcard for any character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dta.violations\n",
    " .str.extract(\"(\\d+)(?=\\.)\", expand=False)\n",
    " .astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how many unique violations do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(\n",
    "    dta.violations\n",
    "        .str.extract(\"(\\d+)(?=\\.)\", expand=False)\n",
    "        .astype(int)\n",
    "        .unique()\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, can we figure out how many times an establishment previously failed an inspection (within the sample we have)? How might we approach this? \n",
    "\n",
    "First, we want to restrict the data to just a single row for each inspection. Since we merged everything with the unstacked violations above, we'll need to use `drop_duplicates` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = dta.drop_duplicates([\"address\", \"dba_name\", \"inspection_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to rely on some pandas time-series functionality to do this, so we will need to ensure that the inspection dates are sorted within each group. GroupBy will preserve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = visits.sort_values([\"address\", \"dba_name\", \"inspection_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = visits.groupby((visits.address, visits.dba_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we might ask, \"now what?\" Remember the trick to pull out groups? Let's use it to work with something we can think about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key = list(grouper.groups.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = grouper.get_group(group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group[['inspection_date', 'results']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we need this to be backwards looking, we will **shift** the data by one visit. Shifting will move the data around by either a number of periods or a frequency. In this case, we use a number of periods and shift forward by 1 period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.shift(1)[['inspection_date', 'results']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take the cumulative sum of this, we'll have an accurate picture of previous failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(group.shift(1).results == 'Fail').cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_num = grouper.apply(lambda df: (df.shift(1).results == 'Fail').cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_num.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(visit_num.reset_index(level=[0, 1], drop=True)\n",
    " .to_frame()\n",
    " .rename(\n",
    "    columns={'results': 'num_fails'}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_num.reset_index(level=[0, 1], drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(visit_num.reset_index(level=[0, 1], drop=True)\n",
    " .to_frame()\n",
    " .rename(\n",
    "    columns={'results': 'num_fails'}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.join((visit_num.reset_index(level=[0, 1], drop=True)\n",
    " .to_frame()\n",
    " .rename(\n",
    "    columns={'results': 'num_fails'}\n",
    ")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
